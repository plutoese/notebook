{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元回归分析：OLS的渐近性质\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一致性\n",
    "\n",
    "“如果你在$n$趋于无穷时还不能正确得到它，那你就不应该干这件事。”（格兰杰）\n",
    "\n",
    "**一致性的直观理解**\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"./pic/w006.jpg\" width = \"50%\" />\n",
    "</div>\n",
    "\n",
    "**定理5.1 OLS的一致性**\n",
    "\n",
    "在假定MLR.1到MLR.4下，对所有的$j=0,1, \\ldots, k$，OLS估计量$\\hat{\\beta}_{j}$都是$\\beta_{j}$的一致估计量。\n",
    "\n",
    "<br>\n",
    "\n",
    "我们表述一个比MLR.4更弱的假定。\n",
    "\n",
    "**假定 MLR.$4^{\\prime}$ （零均值和零相关）**\n",
    "\n",
    "对所有的$j=0,1, \\ldots, k$，都有$E(u)=0$和$\\operatorname{Cov}\\left(x_{i}, u\\right)=0$。\n",
    "\n",
    "对于OLS的一致性，MLR.4的假设可以用更弱的MLR.$4^{\\prime}$取代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 渐近正态和大样本推断\n",
    "\n",
    "**定理5.2 OLS的渐近正态性**\n",
    "\n",
    "在高斯-马尔科夫假定MLR.1到MLR.5下\n",
    "\n",
    "- $\\sqrt{n}\\left(\\hat{\\beta}_{j}-\\beta_{j}\\right) \\stackrel{a}{\\sim} \\text { Normal }\\left(0, \\sigma^{2} / a_{j}^{2}\\right)$，其中$\\sigma^{2} / a_{j}^{2}>0$是$\\sqrt{n}\\left(\\hat{\\beta}_{j}-\\beta_{j}\\right)$的**渐近方差**，至于斜率系数，$a_{j}^{2}=\\operatorname{plim}\\left(n^{-1} \\sum_{i=1}^{n} \\hat{r}_{i j}^{2}\\right)$，其中$\\hat{r}_{i j}$是$x_{j}$对其余自变量进行回归所得到的残差。我们称$\\hat{\\beta}_{j}$为渐近正态分布的。\n",
    "\n",
    "- $\\hat{\\sigma}^{2}$是$\\sigma^{2}=\\operatorname{Var}(u)$的一个一致估计量。\n",
    "\n",
    "- 对每个$j$，都有\n",
    "\n",
    "$$\\frac{\\left(\\widehat{\\beta}_{j}-\\beta_{j}\\right)}{\\operatorname{se}\\left(\\widehat{\\beta}_{j}\\right)} \\stackrel{a}{\\sim} \\text { Normal }(0,1)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "实际上，$\\hat{\\beta}_{j}$的估计方差是\n",
    "\n",
    "$$\\widehat{\\operatorname{Var}\\left(\\hat{\\beta}_{j}\\right)}=\\frac{\\hat{\\sigma}^{2}}{\\operatorname{SST}_{j}\\left(1-R_{j}^{2}\\right)}$$\n",
    "\n",
    "由于$x_{j}$的样本方差是$\\mathrm{SST}_{j} / n$，所以$\\mathrm{SST}_{j} / n$随着样本容量的扩大而收敛于$\\operatorname{Var}\\left(x_{j}\\right)$。因此，$\\widehat{\\operatorname{Var}}\\left(\\hat{\\beta}_{j}\\right)$以速度$1/n$收缩至零，这就说明了样本容量为什么越大越好。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 拉格朗日乘数统计量\n",
    "\n",
    "LM统计量的形式依赖于高斯-马尔科夫假定，但不需要正态性假定。LM统计量仅要求估计约束模型。\n",
    "\n",
    "**$q$个排除性约束的拉格朗日乘数统计量**\n",
    "\n",
    "1. 将$y$对施加限制后的自变量进行回归，并保存残差$\\widetilde{u}$\n",
    "\n",
    "2. 将$\\widetilde{u}$对所有自变量进行回归，并得到$R^{2}$，记为$R_{u}^{2}$。\n",
    "\n",
    "3. 计算$L M=n R_{u}^{2}$\n",
    "\n",
    "4. 将$LM$与$\\chi_{q}^{2}$分布中适当的临界值$c$相比较；如果$L M>c$，就拒绝原假设；否则，我们就不能拒绝原假设。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
