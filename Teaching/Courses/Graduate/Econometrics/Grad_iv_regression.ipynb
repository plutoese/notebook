{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具变量回归\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代理变量\n",
    "\n",
    "**遗漏变量问题的解决方法**\n",
    "\n",
    "- 代理变量\n",
    "\n",
    "- 遗漏变量不随时间而变化，应用固定效应或差分\n",
    "\n",
    "- 工具变量估计\n",
    "\n",
    "方程中因遗漏变量而导致的偏误，解决的可能方式之一是找到遗漏变量的一个代理变量(proxy variable)。\n",
    "\n",
    "<br>\n",
    "\n",
    "**例子：工资方程**\n",
    "\n",
    "一个人的工资水平与他的可测教育水平及其他非观测因素的关系为\n",
    "\n",
    "$$log(wage)=\\beta_{0}+ \\beta_{1}educ + \\beta_{2}exper + \\beta_{3}abil + \\mu$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**遗漏变量的植入解**\n",
    "\n",
    "假设解释变量$x_{3}^{\\ast}$观测不到，但我们有$x_{3}^{\\ast}$的一个代理变量$x_{3}$。首先它要符合基本要求，即它应该和$x_{3}^{\\ast}$有某种关系。\n",
    "\n",
    "$$x_{3}^{\\ast} = \\delta_{0} + \\delta_{1}x_{3} + \\nu_{3}$$\n",
    "\n",
    "对$u$和$\\nu_{3}$的假定\n",
    "\n",
    "- 误差$u$与$x_{1}$,$x_{2}$,$x_{3}^{\\ast}$都不相关，且$u$与$x_{3}$也不相关。\n",
    "\n",
    "- 误差$\\nu_{3}$与$x_{1}$,$x_{2}$,$x_{3}$都不相关，即$E(x_{3}^{\\ast}|x_{1},x_{2},x_{3})=E(x_{3}^{\\ast}|x_{3})$\n",
    "\n",
    "于是，得到\n",
    "\n",
    "$$y = (\\beta{0}+\\beta_{3}\\delta_{0}) + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\beta_{3}\\delta_{3}x_{3} + \\mu + \\beta_{3}\\nu_{3}$$\n",
    "\n",
    "**例子：IQ作为代理变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rio)\n",
    "library(stargazer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================\n",
      "                                   Dependent variable:               \n",
      "                    -------------------------------------------------\n",
      "                                          lwage                      \n",
      "                              (1)                      (2)           \n",
      "---------------------------------------------------------------------\n",
      "educ                       0.0654***                0.0544***        \n",
      "                            (0.0063)                 (0.0069)        \n",
      "                                                                     \n",
      "exper                      0.0140***                0.0141***        \n",
      "                            (0.0032)                 (0.0032)        \n",
      "                                                                     \n",
      "tenure                     0.0117***                0.0114***        \n",
      "                            (0.0025)                 (0.0024)        \n",
      "                                                                     \n",
      "married                    0.1994***                0.1998***        \n",
      "                            (0.0391)                 (0.0388)        \n",
      "                                                                     \n",
      "south                      -0.0909***               -0.0802***       \n",
      "                            (0.0262)                 (0.0263)        \n",
      "                                                                     \n",
      "urban                      0.1839***                0.1819***        \n",
      "                            (0.0270)                 (0.0268)        \n",
      "                                                                     \n",
      "black                      -0.1883***               -0.1431***       \n",
      "                            (0.0377)                 (0.0395)        \n",
      "                                                                     \n",
      "IQ                                                  0.0036***        \n",
      "                                                     (0.0010)        \n",
      "                                                                     \n",
      "Constant                   5.3955***                5.1764***        \n",
      "                            (0.1132)                 (0.1280)        \n",
      "                                                                     \n",
      "---------------------------------------------------------------------\n",
      "Observations                  935                      935           \n",
      "R2                           0.2526                   0.2628         \n",
      "Adjusted R2                  0.2469                   0.2564         \n",
      "Residual Std. Error    0.3655 (df = 927)        0.3632 (df = 926)    \n",
      "F Statistic         44.7471*** (df = 7; 927) 41.2650*** (df = 8; 926)\n",
      "=====================================================================\n",
      "Note:                                     *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "wage2_data <- import(\"https://p193.p3.n0.cdn.getcloudapp.com/items/NQugkbB4/WAGE2.DTA\")\n",
    "\n",
    "lmobj1 <- lm(lwage ~ educ + exper + tenure + married + south + urban + black, data=wage2_data)\n",
    "lmobj2 <- lm(lwage ~ educ + exper + tenure + married + south + urban + black + IQ, data=wage2_data)\n",
    "\n",
    "stargazer(lmobj1, lmobj2, type=\"text\", header = TRUE, digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用滞后因变量作为代理变量**\n",
    "\n",
    "我们可以将较早时期的因变量值包括进来加以控制，这种方法对政策分析特别有用。\n",
    "\n",
    "**例子：城市犯罪率**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================\n",
      "                                Dependent variable:            \n",
      "                    -------------------------------------------\n",
      "                                      lcrmrte                  \n",
      "                            (1)                   (2)          \n",
      "---------------------------------------------------------------\n",
      "unem                      -0.0290               0.0086         \n",
      "                         (0.0323)              (0.0195)        \n",
      "                                                               \n",
      "llawexpc                  0.2034                -0.1396        \n",
      "                         (0.1727)              (0.1086)        \n",
      "                                                               \n",
      "lcrmrt_1                                       1.1939***       \n",
      "                                               (0.1321)        \n",
      "                                                               \n",
      "Constant                 3.3429**               0.0765         \n",
      "                         (1.2505)              (0.8211)        \n",
      "                                                               \n",
      "---------------------------------------------------------------\n",
      "Observations                46                    46           \n",
      "R2                        0.0571                0.6798         \n",
      "Adjusted R2               0.0133                0.6570         \n",
      "Residual Std. Error  0.3231 (df = 43)      0.1905 (df = 42)    \n",
      "F Statistic         1.3024 (df = 2; 43) 29.7267*** (df = 3; 42)\n",
      "===============================================================\n",
      "Note:                               *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "crime_data <- import(\"https://p193.p3.n0.cdn.getcloudapp.com/items/Wnub2d58/CRIME2.DTA?\")\n",
    "crime_data_87 <- crime_data[crime_data$year==87,]\n",
    "\n",
    "lmobj1 <- lm(lcrmrte ~ unem + llawexpc, data=crime_data_87)\n",
    "lmobj2 <- lm(lcrmrte ~ unem + llawexpc + lcrmrt_1, data=crime_data)\n",
    "\n",
    "stargazer(lmobj1, lmobj2, type=\"text\", header = TRUE, digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归模型的工具变量估计\n",
    "\n",
    "### 工具变量基本假定\n",
    "\n",
    "设有一个可观测的变量$z$，它满足两个假定\n",
    "\n",
    "- 工具外生性：$Cov(z,\\mu) = 0$\n",
    "\n",
    "- 工具相关性：$Cov(z,x) \\neq 0$\n",
    "\n",
    "我们则称$z$是$x$的工具变量，有时候也简称为$x$的工具。\n",
    "\n",
    "<br>\n",
    "\n",
    "**工具变量要求的说明**\n",
    "\n",
    "工具变量的两个要求之间有一个非常重要的差别。工具外生性通常无法对它进行检验。绝大多数情形中，我们必须借助于经济行为或反思来维持这一假定。相比之下，给定一个来自总体的随机样本，$z$与$x$相关的条件则可加以检验。做到这一点最容易的方法是估计一个$x$与$z$之间的简单回归。\n",
    "\n",
    "$$x=\\pi_{0} + \\pi_{1}z + \\upsilon$$\n",
    "\n",
    "如果能够在充分小的显著性水平上，拒绝原假设$H_{0}:\\pi_{1}=0$，那么就有相当把握肯定相关性条件是成立的。\n",
    "\n",
    "<br>\n",
    "\n",
    "**例子：教育的工具变量**\n",
    "\n",
    "对于工资方程来说，教育的工具变量$z$必须满足两个假定\n",
    "\n",
    "- $z$必须与能力（以及其他影响工资的无法观测因素）不相关\n",
    "\n",
    "- $z$与教育相关\n",
    "\n",
    "**教育的工具变量选择**\n",
    "\n",
    "- 例如选择一个人的社会保险号中最后一位数字作为教育的工具变量是糟糕的，因为其随机性，所以虽然它是外生的，但也与教育不相关。\n",
    "\n",
    "- 能力的代理变量应该与能力高度相关，而工具变量必须与能力不相关。因此，尽管IQ作为能力的一个备选代理不错，但是作为教育的工具变量却很糟糕。\n",
    "\n",
    "- 母亲的教育\n",
    "\n",
    "- 兄弟姐妹的数目\n",
    "\n",
    "<br>\n",
    "\n",
    "**例子：逃课对期末考试成绩的因果影响**\n",
    "\n",
    "我们可能担心逃课的总次数与影响期末考试成绩的其他因素相关，例如越有能力而又积极的学生可能逃课也越少。一个IV的选择是住宿区与学校之间的距离。但误差中的一些因素可能与距离相关。例如，低收入家庭的学生可能不住在学校；若收入影响成绩，可能会导致距离与误差相关。\n",
    "\n",
    "<br>\n",
    "\n",
    "**例子：制度对一国的人均收入的因果影响**\n",
    "\n",
    "阿西莫格鲁等在一项经典研究( Acemoglu et al．，2001) 中， 把殖民地时代一个国家的自然死亡率作为该国当今制度的工具变量。其理由非常巧妙: 如果该地区当年的死亡率高，那么欧洲殖民者就相对不愿定居下来， 从而在当地建立起更具掠夺性的“坏”制度。由于制度的“路径依赖”， 殖民时代的制度显然和现在的制度关系密切。因此， 历史上的死亡率作为工具变量， 应该和当今制度紧密相关， 而一百年前的死亡率作为一种自然生理现象， 又和目前的人均收入没有直接关系。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 简单线性回归的工具变量估计量\n",
    "\n",
    "给定随机样本，对应样本量来估计总体量，可以得到$\\beta_{1}$的工具变量（IV）估计量\n",
    "\n",
    "$$\\hat{\\beta}_{1}=\\frac{\\sum_{i=1}^{n} (z_{i}-\\bar{z})(y_{i}-\\bar{y})}{\\sum_{i=1}^{n} (z_{i}-\\bar{z})(x_{i}-\\bar{x})}$$\n",
    "\n",
    "当$z=x$时，我们获得$\\beta_{1}$的OLS估计量。意味着当$x$外生时，它可以用作自身的IV。\n",
    "\n",
    "当满足工具变量的两个假定时，$\\beta_{1}$的IV估计量具有一致性\n",
    "\n",
    "$$plim(\\hat{\\beta}_{1})=\\beta_{1}$$\n",
    "\n",
    "IV估计量的一个特定是：当事实上$x$与$\\mu$相关时，它实质上绝不是无偏的。在小样本中，这意味着IV估计量可能有相当大的偏误，这就是为什么希望有大样本的一个原因。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 工具变量估计量的渐近方差\n",
    "\n",
    "在工具变量的假定增加同方差假定$E(\\mu^{2}|z)=\\sigma^{2}=Var(\\mu)$，则$\\hat{\\beta}_{1}$的渐近方差为\n",
    "\n",
    "$$\\frac{\\sigma^{2}}{n\\sigma^{2}_{x}\\rho^{2}_{x,z}}$$\n",
    "\n",
    "经过一些转换，IV估计量的渐近方差可以由下式给出\n",
    "\n",
    "$$\\frac{\\hat{\\sigma}^{2}}{SST_{x}R_{x,z}^{2}}$$\n",
    "\n",
    "在大样本的情况下，IV估计量近似服从正态分布。IV估计量和OLS估计量的渐近方差分别为\n",
    "\n",
    "$$\\hat{\\beta}_{1,IV} = \\frac{\\sigma^{2}}{SST_{x}R_{x,z}^{2}}, \\hat{\\beta}_{1,OLS} = \\frac{\\sigma^{2}}{SST_{x}}$$\n",
    "\n",
    "当$x$与$\\mu$不相关时进行IV估计的一个重要代价：IV估计量的渐近方差总是大于(有时远大于)OLS估计量的渐近方差。\n",
    "\n",
    "**例子：估计已婚女性的教育回报**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================\n",
      "                                        Dependent variable:         \n",
      "                               -------------------------------------\n",
      "                                               lwage                \n",
      "                                         OLS            instrumental\n",
      "                                                          variable  \n",
      "                                         (1)                (2)     \n",
      "--------------------------------------------------------------------\n",
      "educ                                  0.1086***           0.0592*   \n",
      "                                       (0.0144)           (0.0351)  \n",
      "                                                                    \n",
      "Constant                               -0.1852             0.4411   \n",
      "                                       (0.1852)           (0.4461)  \n",
      "                                                                    \n",
      "--------------------------------------------------------------------\n",
      "Observations                             428                428     \n",
      "R2                                      0.1179             0.0934   \n",
      "Adjusted R2                             0.1158             0.0913   \n",
      "Residual Std. Error (df = 426)          0.6800             0.6894   \n",
      "F Statistic                    56.9289*** (df = 1; 426)             \n",
      "====================================================================\n",
      "Note:                                    *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "library(AER)\n",
    "\n",
    "mroz_data <- import(\"https://p193.p3.n0.cdn.getcloudapp.com/items/mXuAdj0A/MROZ.DTA\")\n",
    "\n",
    "lmobj1 <- lm(lwage ~ educ, data=mroz_data)\n",
    "lmobj2 <- ivreg(lwage ~ educ|fatheduc, data=mroz_data)\n",
    "\n",
    "stargazer(lmobj1, lmobj2, type=\"text\", header = TRUE, digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 低劣工具变量条件下IV的性质\n",
    "\n",
    "$z$和$x$之间的弱相关可能产生严重的后果，这时，即便$z$和$\\mu$只是适度相关，IV估计量的渐近偏误也可能很大。\n",
    "\n",
    "$$plim \\hat{\\beta}_{1,IV} = \\beta_{1} + \\frac{Corr(z,u)}{Corr(z,x)}\\frac{\\sigma_{u}}{\\sigma_{x}}$$\n",
    "\n",
    "$$plim \\hat{\\beta}_{1,OLS} = \\beta_{1} + Corr(x,u)\\frac{\\sigma_{u}}{\\sigma_{x}}$$\n",
    "\n",
    "比较这两个公式发现，IV和OLS渐近偏误的方向可能是不同的。此外，如果$Corr(z,x)$很小，那么$z$和$\\mu$之间看似很小的相关性就可能被放大。例如$Corr(z,x)=0.2$，那么，欲使IV比OLS具有更小的渐近偏误，$Corr(z,u)$必须小于$Corr(x,u)$的五分之一。\n",
    "\n",
    "实践中特别有意思的所谓弱工具(weak instruments)，就被大致定义为$z$和$x$之间的相关度”很低“(但不为零)的问题。\n",
    "\n",
    "<br>\n",
    "\n",
    "### IV估计后计算$R^{2}$\n",
    "\n",
    "- 大多数回归软件包运用标准公式$R^{2}=1-SSR/SST$计算IV估计之后的$R^{2}$，其中$SSR$是IV残差的平方和。与OLS中的情况不同，由于IV的$SSR$实际上可能大于$SST$，所以IV估计中的$R^{2}$可能为负。\n",
    "\n",
    "- 当$x$与$\\mu$相关时，我们不能将$y$的方差分解成$\\beta^{2}_{1}Var(x)+Var(\\mu)$，因此对$R^{2}$没有合理的解释。\n",
    "\n",
    "- 如果不能一致地估计$\\beta_{1}$，从OLS中得到再高的$R^{2}$也不会令人欣慰。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 多元回归模型的IV估计\n",
    "\n",
    "考虑两个解释变量的标准线性模型\n",
    "\n",
    "$$y_{1} = \\beta_{0} + \\beta_{1}y_{2} + \\beta_{2}z_{1} + \\mu_{1}$$\n",
    "\n",
    "我们称之为结构方程。如果用OLS估计，所有的估计量将是有偏且又不一致的。因此，我们寻找一个$y_{2}$的工具$z_{2}$，则关键假定为\n",
    "\n",
    "- $E(\\mu_{1}) = 0$\n",
    "\n",
    "- $Cov(z_{1},\\mu_{1}) = E(z_{1}\\mu_{1}) = 0$\n",
    "\n",
    "- $Cov(z_{2},\\mu_{1}) = E(z_{2}\\mu_{1}) = 0$\n",
    "\n",
    "给定零均值假定，后两个假定等价于$E(z_{1}\\mu_{1})=0$和$E(z_{2}\\mu_{2})=0$。因而可以通过矩估计法来求解三个相应的样本方程，得到工具变量估计量。\n",
    "\n",
    "我们需要工具变量$z_{2}$和$y_{2}$偏相关，即回归模型\n",
    "\n",
    "$$y_{2} = \\pi_{0} + \\pi_{1}z_{1} + \\pi_{2}z_{2} + \\nu_{2}$$\n",
    "\n",
    "此为约简型方程的一个例子。关键的识别条件是$\\pi_{2} \\neq 0$。换句话说，排除了$z_{1}$的影响后，$y_{2}$与$z_{2}$仍然相关。我们通过OLS估计上式，并使用$t$检验。我们应当时常检验这一假定。不幸的是，我们不能检验外生性，智能寄希望于经济逻辑和反思。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两阶段最小二乘法（$2SLS$）\n",
    "\n",
    "### 单个内生解释变量\n",
    "\n",
    "考虑一个简单的工资方程\n",
    "\n",
    "$$\\text {wages}=\\beta_{0}+\\beta_{1} \\text {educ}+\\mu$$\n",
    "\n",
    "如果$educ$是内生变量，考虑如下两个工具变量：$fed$（父亲的教育程度）和$med$（母亲的教育程度），一般有\n",
    "\n",
    "$$\\hat{\\beta}_{1}^{f e d}=\\frac{cov (\\text {wages,fed})}{cov (e d u c, f e d)} \\neq \\hat{\\beta}_{1}^{m e d}=\\frac{cov (\\text {wages,med})}{cov (e d u c, m e d)}$$\n",
    "\n",
    "那么到底该用哪个工具呢？\n",
    "\n",
    "<br>\n",
    "\n",
    "现在假定有两个被排斥在模型之外的外生变量：$z_{2}$和$z_{3}$。$z_{2}$和$z_{3}$不出现在模型中，且与误差项$u_{1}$不相关的假定被称为**排除性约束**(exclusion restrictions)。\n",
    "\n",
    "为寻找最好的IV，我们选择与$y_{2}$最高度相关的线性组合。\n",
    "\n",
    "$$y_{2} = \\pi_{0} + \\pi_{1}z_{1} + \\pi_{2}z_{2} + \\pi_{3}z_{3} + \\nu_{2}$$\n",
    "\n",
    "那么，$y_{2}$最好的IV是上式中$z_{j}$的线性组合，我们称之为$y_{2}^{\\ast}$：\n",
    "\n",
    "$$y_{2}^{\\ast} = \\pi_{0} + \\pi_{1}z_{1} + \\pi_{2}z_{2} + \\pi_{3}z_{3}$$\n",
    "\n",
    "关键识别假定为：$\\pi_{2} \\neq 0$或$\\pi_{3} \\neq 0$\n",
    "\n",
    "我们将$y_{2}$对$z_{1}$,$z_{2}$,$z_{3}$回归，获得拟合值$\\hat{y}_{2}$。我们就可以用它作为$y_{2}$的IV。利用三个假定：\n",
    "\n",
    "- $E(\\mu_{1}) = 0$\n",
    "\n",
    "- $Cov(z_{1},\\mu_{1}) = E(z_{1}\\mu_{1}) = 0$\n",
    "\n",
    "- $Cov(y_{2}^{\\ast},\\mu_{1}) = E(y_{2}^{\\ast}\\mu_{1}) = 0$\n",
    "\n",
    "求解三个正规方程，得到IV估计量。在多重工具条件下，IV估计量也叫作两阶段最小二乘($2SLS$)估计量。原因很简单，当我们用$\\hat{y}_{2}$作为$y_{2}$的IV时，IV估计值$\\hat{\\beta}_{0}$，$\\hat{\\beta}_{1}$和$\\hat{\\beta}_{2}$等同于从$y_{1}$对$\\hat{y}_{2}$和$z_{1}$的回归中得到的OLS估计值。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 多重共线性与$2SLS$\n",
    "\n",
    "$\\beta_{1}$的$2SLS$估计量的(渐近)方差近似地写为：\n",
    "\n",
    "$$\\frac{\\sigma^{2}}{\\hat{SST}_{2}(1-\\hat{R}_{2}^{2})}$$\n",
    "\n",
    "其中，$\\sigma^{2} = Var(\\mu_{1})$，$\\hat{SST}_{2}$是$\\hat{y}_{2}$的总波动，$\\hat{R}_{2}^{2}$是将$\\hat{y}_{2}$对其他所有出现在结构方程中的外生变量做回归得到的$R^{2}$。$2SLS$的方差大于OLS的方差的原因有二。\n",
    "\n",
    "- 根据构造，$\\hat{y}_{2}$比$y_{2}$的波动性更小。\n",
    "\n",
    "- $\\hat{y}_{2}$与方程中外生变量之间的相关往往比$y_{2}$与这些变量之间的相关大得多。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 多个内生解释变量与方程识别阶条件\n",
    "\n",
    "一般地，当我们在回归模型中有不止一个内生解释变量是，有可能遇到无法识别的问题。但是，我们可以容易地表述识别的一个必要条件，叫做阶条件。**方程识别的阶条件**：我们需要被排斥的外生变量至少与结构方程中包括的内生解释变量一样多。\n",
    "\n",
    "<br>\n",
    "\n",
    "### $2SLS$估计后对多个假设的检验\n",
    "\n",
    "$2SLS$中的$R^{2}$可能为负的事实表明，通常计算$F$统计量的方法可能不适合。有可能将第二阶段回归得到的残差平方和与$SSR_{ur}$结合起来，以获得一个在大样本下近似服从$F$分布的统计量。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 变量误差问题的IV解决方法\n",
    "\n",
    "**解释变量中的测量误差**\n",
    "\n",
    "简单回归模型\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}x^{*}_{1}+\\mu$$\n",
    "\n",
    "假设它至少满足前$4$个高斯-马尔可夫假定。测量误差是\n",
    "\n",
    "$$e_{1}=x_{1}-x_{1}^{*}$$\n",
    "\n",
    "代入原方程得到\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}x_{1}+(\\mu-\\beta_{1}e_{1})$$\n",
    "\n",
    "OLS的性质关键取决于对测量误差所做的假定。第一个假定是，$e_{1}$与所观测到的测量值$x_{1}$不相关，即\n",
    "\n",
    "$$Cov(x_{1},e_{1})=0$$\n",
    "\n",
    "若假定正确，除非$\\beta_{1}=0$，否则测量误差就会提高误差方差，但并不会影响任何一个OLS性质。\n",
    "\n",
    "另一个是经典变量误差（CEV）假定，指测量误差与无法观测的解释变量无关，即\n",
    "\n",
    "$$Cov(x^{*}_{1},e_{1})=0$$\n",
    "\n",
    "若上述假定成立，那么$x_{1}$与$e_{1}$就一定相关\n",
    "\n",
    "$$Cov(x_{1},e_{1})=E(x_{1}e_{1})=E(x_{1}^{*}e_{1})+E(e_{1}^{2})=\\sigma^{2}_{e_{1}}$$\n",
    "\n",
    "由于$\\mu$和$x_{1}$无关，所以$x_{1}$与合成误差$\\mu-\\beta_{1}e_{1}$之间的协方差就是\n",
    "\n",
    "$$Cov(x_{1},\\mu-\\beta_{1}e_{1}) = -\\beta_{1}Cov(x_{1},e_{1})=-\\beta_{1}\\sigma^{2}_{e_{1}}$$\n",
    "\n",
    "因此，在CEV情形下，$y$对$x_{1}$的OLS回归将给出一个有偏而又不一致的估计量。\n",
    "\n",
    "**IV解决方法**\n",
    "\n",
    "考虑模型\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}x^{*}_{1}+\\beta_{2}x_{2}+\\mu$$\n",
    "\n",
    "令$x_{1}$是$x^{*}_{1}$的一个可观测度量，$x_{1}=x^{*}_{1}+e_{1}$。由于$x_{1}$和$e_{1}$相关，因此需要$x_{1}$的IV。一种可能是获取$x^{*}_{1}$的第二个度量$z_{1}$。另一个选择是运用其他外生变量，将它们作为潜在误测变量的IV。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 内生性检验和过度识别约束检验\n",
    "\n",
    "### 内生性检验\n",
    "\n",
    "在解释变量外生时，2SLS估计量的有效性不如OLS。因此，有必要检验解释变量的内生性。假定我们仅有一个疑似内生变量\n",
    "\n",
    "$$y_{1} = \\beta_{0} + \\beta_{1}y_{2} + \\beta_{2}z_{1} + \\beta_{3}z_{2} + \\mu_{1}$$\n",
    "\n",
    "豪斯曼(Hausman) 建议直接比较OLS和2SLS估计值，判断其差异是否在统计上显著。\n",
    "\n",
    "为了判断两者是否显著不同，利用回归来检验似乎更加方便。此处为\n",
    "\n",
    "$$y_{2} = \\pi_{0} + \\pi_{1}z_{1} + \\pi_{2}z_{2} + \\pi_{3}z_{3} + \\pi_{4}z_{4} + \\nu_{2}$$\n",
    "\n",
    "因此，$y_{2}$与$\\mu_{1}$不相关的重要条件是$\\nu_{2}$与$\\mu_{1}$不相关。可以写成$\\mu_{1}=\\delta_{1}\\nu_{2}+e_{1}$。因此，我们用OLS估计\n",
    "\n",
    "$$y_{1} = \\beta_{0} + \\beta_{1}y_{2} + \\beta_{2}z_{1} + \\beta_{3}z_{2} + \\delta_{1}\\nu_{2} + e_{1}$$\n",
    "\n",
    "并用$t$统计量检验：$H_{0}$：$\\delta_{1}=0$\n",
    "\n",
    "**检验单个解释变量的内生性的步骤**\n",
    "\n",
    "- 通过将$y_{2}$对所有外生变量回归，得到残差$\\hat{v}_{2}$。\n",
    "\n",
    "- 在结构方程中添加$\\hat{v}_{2}$，并用一个OLS回归检验$\\hat{v}_{2}$的显著性。若其系数统计上显著异于零，我们便判断$y_{2}$确实是内生的。\n",
    "\n",
    "<br>\n",
    "\n",
    "### 过度识别约束检验\n",
    "\n",
    "如果我们所拥有的工具多于得到一致估计结果所需要的工具数量，就能有效地检验它们中的一部分是否与误差不相关。其思想是，如果所有的工具都是外生的，那么，除了抽样误差外，**$2SLS$残差与工具应该不相关，且与这些工具的线性组合都不相关**。\n",
    "\n",
    "**过度识别约束检验的步骤**\n",
    "\n",
    "- 用$2SLS$估计结构方程，获得$2SLS$残差$\\hat{\\mu}_{1}$。\n",
    "\n",
    "- 将$\\hat{\\mu}_{1}$对所有外生变量回归，得到$R^{2}$，即$R_{1}^{2}$。\n",
    "\n",
    "- 在所有的IV都与$\\mu_{1}$不相关的原假设下，$nR_{1}^{2} \\sim \\chi_{q}^{2}$，其中$q$是模型之外的工具变量减去内生解释变量的总数目。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
